# -*- coding: utf-8 -*-
"""project_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cExvOx1o5KAG5fTzS_KMUB4c_ENZnzoY

# üõçÔ∏è Project Notebook
Section UU
- Vanessa DiPietrantonio 40189938
- Micha√´l Gugliandolo 40213419
- Jessey Thach 40210440
- Mahanaim Rubin Yo 40178119

## üì• Part 1: Data Preprocessing
Steps:
- Load `ecommerce_user_data.csv` and `product_details.csv`
- Merge data if necessary
- Create user-item matrix
- Fill missing ratings with 0
- Group user behavior by category
"""

# Load data
import pandas as pd

user_data = pd.read_csv('data/ecommerce_user_data.csv')
product_data = pd.read_csv('data/product_details.csv')

print(user_data.head())
print(product_data.head())

# Merge datasets on ProductID to get complete info
data = pd.merge(user_data, product_data, on='ProductID', how='left')
print(data.head())

# Create user-item matrix
user_item_matrix = user_data.pivot_table(index='UserID', columns='ProductID', values='Rating')
user_item_matrix_filled = user_item_matrix.fillna(0)
print(user_item_matrix_filled.head())

# Aggregate user behavior by category
user_category_agg = user_data.groupby(['UserID', 'Category']).agg({'Rating': ['count', 'mean']}).reset_index()
user_category_agg.columns = ['UserID', 'Category', 'TotalInteractions', 'AverageRating']
print(user_category_agg.head())

"""## ü§ù Part 2: User-Based Collaborative Filtering
Steps:
- Use cosine similarity to compare users
- Recommend top-N products based on similar users
- Evaluate with Precision@K and Coverage
"""

# Compute cosine similarity
from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix = cosine_similarity(user_item_matrix_filled)
similarity_df = pd.DataFrame(similarity_matrix, index=user_item_matrix_filled.index, columns=user_item_matrix_filled.index)
print(similarity_df.head())

# Create recommendation function
# Find most similar user, recommend products they rated highly that target user hasn‚Äôt rated

# Function to get top-N similar users for a given user
def get_top_similar_users(user_id, similarity_matrix, n=3):
    # Exclude the target user and sort by similarity
    similar_scores = similarity_matrix.loc[user_id].drop(user_id)
    top_users = similar_scores.nlargest(n).index.tolist()
    return top_users

# Function to generate product recommendations for a given user
def recommend_products(user_id, matrix, similarity_matrix, n_similar=3, top_n=5):
    top_users = get_top_similar_users(user_id, similarity_matrix, n=n_similar)
    similar_ratings = matrix.loc[top_users]
    user_rated = matrix.loc[user_id]

    scores = {}
    for product in matrix.columns:
        if user_rated[product] == 0:
            scores[product] = similar_ratings[product].mean()

    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    rec_df = pd.DataFrame(sorted_scores[:top_n], columns=['ProductID', 'AvgRating'])
    recommend_products = rec_df.merge(product_data, on='ProductID', how='left')
    return recommend_products

example_user = user_item_matrix.index[0]
print(f"Top recommendations for {example_user}:")
print(recommend_products(example_user, user_item_matrix_filled, similarity_df))

# Implement evaluation metrics like Precision@K and Coverage
# Example: compare recommended vs actual rated items
import random
import numpy as np
from sklearn.metrics import average_precision_score

# Train/test split
def train_test_split(matrix, test_ratio=0.2):
    train = matrix.copy()
    test = pd.DataFrame(0, index=matrix.index, columns=matrix.columns)

    for user in matrix.index:
        rated_items = matrix.loc[user][matrix.loc[user] > 0].index.tolist()
        n_test = int(len(rated_items) * test_ratio)
        test_items = random.sample(rated_items, n_test) if n_test > 0 else []
        train.loc[user, test_items] = 0
        test.loc[user, test_items] = matrix.loc[user, test_items]

    return train, test

# Split the data
train_matrix, test_matrix = train_test_split(user_item_matrix_filled)

# Recalculate similarity on training data
train_similarity = pd.DataFrame(cosine_similarity(train_matrix), index=train_matrix.index, columns=train_matrix.index)

# Evaluation metrics
def precision_at_k(user, recs, test_data, k=5, threshold=3):
    relevant = test_data.loc[user][test_data.loc[user] >= threshold].index.tolist()
    predicted = recs['ProductID'].tolist() if not recs.empty else []
    hits = len(set(relevant) & set(predicted))
    return hits / k

def recall_at_k(user, recs, test_data, k=5, threshold=3):
    relevant = test_data.loc[user][test_data.loc[user] >= threshold].index.tolist()
    if not relevant:
        return 0
    predicted = recs['ProductID'].tolist() if not recs.empty else []
    hits = len(set(relevant) & set(predicted))
    return hits / len(relevant)

# Evaluate on all users
precisions, recalls, maps = [], [], []
recommendation_dict = {}

precisions, recalls, maps = [], [], []
recommendation_dict = {}

for user in train_matrix.index:
    recs = recommend_products(user, train_matrix, train_similarity)
    recommendation_dict[user] = recs['ProductID'].tolist() if not recs.empty else []

    # Precision & Recall
    p = precision_at_k(user, recs, test_matrix)
    r = recall_at_k(user, recs, test_matrix)
    precisions.append(p)
    recalls.append(r)

    # MAP
    relevant_items = test_matrix.loc[user]
    y_true = (relevant_items >= 3).astype(int)
    y_scores = pd.Series(0, index=train_matrix.columns)

    if not recs.empty:
        for product in recs['ProductID']:
            if product in y_scores.index:
                y_scores[product] = 1
        try:
            maps.append(average_precision_score(y_true, y_scores))
        except:
            maps.append(0)
    else:
        maps.append(0)

print(f"\n--- Evaluation Summary ---")
print(f"Precision@5: {np.mean(precisions):.4f}")
print(f"Recall@5   : {np.mean(recalls):.4f}")
print(f"MAP        : {np.mean(maps):.4f}")

# Coverage: % of unique items recommended to all users
all_recommended_items = set(p for recs in recommendation_dict.values() for p in recs)
coverage = len(all_recommended_items) / len(train_matrix.columns)
print(f"Coverage   : {coverage:.4f}")

"""## üîç Part 3: Association Rule Mining (Apriori)
Steps:
- Convert user-product interactions to transaction format
- Apply Apriori algorithm to find frequent itemsets
- Generate association rules (support, confidence, lift)
"""

# Convert to transaction format
from mlxtend.preprocessing import TransactionEncoder
transactions = user_data.groupby('UserID')['ProductID'].apply(list).tolist()
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_trans = pd.DataFrame(te_ary, columns=te.columns_)
print(df_trans.head())

# Apply Apriori and generate rules
from mlxtend.frequent_patterns import apriori, association_rules

frequent_itemsets = apriori(df_trans, min_support=0.05, use_colnames=True)
rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())

"""## üìä Part 4: Visualization
Steps:
- Plot user similarity heatmap
- Plot top frequent itemsets
- Visualize top recommendations
"""

# Heatmap of user similarity
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.heatmap(similarity_df, cmap='YlGnBu')
plt.title('User Similarity Heatmap')
plt.show()

# Frequent itemsets bar chart
frequent_itemsets.nlargest(10, 'support').plot(kind='bar', x='itemsets', y='support', legend=False)
plt.title('Top 10 Frequent Itemsets')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Visualize top recommendations for an example user.
# Generate recommendations for an example user.
example_user = user_item_matrix_filled.index[0]
top_recs = recommend_products(example_user, user_item_matrix_filled, similarity_df)

plt.figure(figsize=(10, 6))
plt.bar(top_recs['ProductName'], top_recs['AvgRating'])
plt.title(f"Top Recommendations for User {example_user}")
plt.xticks(rotation=45, ha='right')
plt.ylabel("Average Rating")
plt.tight_layout()
plt.savefig("top_recommendations.png")
plt.show()